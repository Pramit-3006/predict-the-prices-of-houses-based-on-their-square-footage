# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gc2bxV-z0XtAIDWt5rcFndVkPZgLLCHo
"""

import pandas as pd

# Load the dataset
file_path = "/content/House Price Prediction Dataset.csv"
df = pd.read_csv(file_path)

# Display the first few rows of the dataset
df.head()

# Check for missing values
df.isnull().sum()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Select features and target variable
X = df[['Area', 'Bedrooms', 'Bathrooms']]
y = df['Price']

# Split the dataset into training (80%) and testing (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

mae, mse, r2

import matplotlib.pyplot as plt
import seaborn as sns

# Scatter plots to visualize relationships between features and price
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

sns.scatterplot(x=df["Area"], y=df["Price"], ax=axes[0])
axes[0].set_title("Area vs Price")

sns.scatterplot(x=df["Bedrooms"], y=df["Price"], ax=axes[1])
axes[1].set_title("Bedrooms vs Price")

sns.scatterplot(x=df["Bathrooms"], y=df["Price"], ax=axes[2])
axes[2].set_title("Bathrooms vs Price")

plt.show()

# Correlation heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(df[['Area', 'Bedrooms', 'Bathrooms', 'Price']].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Feature Correlation Heatmap")
plt.show()

from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Create a polynomial regression model (degree 2)
poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())
poly_model.fit(X_train, y_train)

# Predict using the polynomial model
y_poly_pred = poly_model.predict(X_test)

# Evaluate polynomial regression
poly_mae = mean_absolute_error(y_test, y_poly_pred)
poly_mse = mean_squared_error(y_test, y_poly_pred)
poly_r2 = r2_score(y_test, y_poly_pred)

poly_mae, poly_mse, poly_r2

# Plot Actual vs. Predicted Prices
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5, label="Linear Regression")
plt.scatter(y_test, y_poly_pred, alpha=0.5, label="Polynomial Regression", color='red')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='black', label="Perfect Prediction")

plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs. Predicted House Prices")
plt.legend()
plt.show()